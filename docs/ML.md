# Процесс обучения

Для достижения поставленной цели было необходимо выполнить несколько основных задач:
- разметка данного датасета
- выбор и обучение модели
- разработка REST API сервиса

Основную сложность составляля именно первая задача.

> [!Note]
> Проект использует [uv](https://github.com/astral-sh/uv) для управления зависимостями.
> Перед выполнением любых команд ниже необходимо выполнить `uv sync`

## Разметка данных

Для разметки данных было использовано несколько подходов, подробнее описанных в [экспериментах](EXPERIMENTS.md).
Однако, все подходы производили аннотацию изображений в два этапа:
1) Нахождение в изображении всех логотип с помощью модели [Grounding Dino](https://github.com/IDEA-Research/GroundingDINO)
2) Аннотация локализованных логотипов с помощью [CLIP](https://github.com/mlfoundations/open_clip) модели

Найденные Grounding Dino логотипы сохранятся в файловой системе в специальном формате 'boxes'.
Пусть изображение имеет название `nice_image.jpg` и имеет 2 найденных логотипа.
Тогда создаваемым `boxes` является директория следуюего вида:
```
nice_image/
├── 0.jpg
├── 1.jpg
└── metadata.json
```
Файлы `0.jpg` и `1.jpg` содержан локализованные логотипы, а `metadata.json` их нормированное положение в формате `center_x center_y width height`.
Директории такого вида далее обрабатываются моделью CLIP.
Реализация находится в модуле data.

Для нахождения логотипов с помощью Grounding Dino см.:
```python
uv run -m tbank_logo_detector.data detect --help
```

Для аннотации полученных на прошлом этапе boxes см.:
```python
uv run -m tbank_logo_detector.data annotate --help
```

## Обучение модели
На данный момент базовыми моделями являются YOLOv8 и YOLOv11 от Utralytics.
Датасет, предоставляемый YOLO, должен находится в пути, указанном в [файле конфигурации](../configs/yolo_dataset.yaml).
Использовались командой ultralytics веса.

Процесс обучения модели реализован в модуле model.
Для обучения см. подробнее:
```python
uv run -m tbank_logo_detector.model train --help
```
